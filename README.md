## Credit Scoring Engine â€“ ImplÃ©mentation MLOps complÃ¨te

##ğŸ“Œ Contexte
Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre dâ€™une mission au sein de lâ€™entreprise fictive "PrÃªt Ã  dÃ©penser", spÃ©cialisÃ©e dans les crÃ©dits Ã  la consommation pour des clients sans historique de crÃ©dit.
Lâ€™objectif est de dÃ©velopper un outil de scoring crÃ©dit, permettant de prÃ©dire la probabilitÃ© de remboursement dâ€™un client et de classifier les demandes en crÃ©dit accordÃ© ou refusÃ©, tout en suivant une dÃ©marche MLOps complÃ¨te.

## ğŸ¯ Objectifs du projet
- Ã‰laborer un modÃ¨le de classification supervisÃ©e robuste et interprÃ©table.

- CrÃ©er un score mÃ©tier basÃ© sur le coÃ»t diffÃ©renciÃ© des erreurs (faux nÃ©gatifs / faux positifs).

- Mettre en Å“uvre une infrastructure MLOps avec versionning, CI/CD et monitoring.

- DÃ©ployer le modÃ¨le via une API FastAPI connectÃ©e Ã  une interface utilisateur Streamlit.

- Suivre la dÃ©rive des donnÃ©es (data drift) Ã  lâ€™aide de la librairie Evidently.

## ğŸ› ï¸ Stack technique
- Python (Pandas, Scikit-Learn, XGBoost)

- FastAPI (API Backend)

- Streamlit (Frontend de test)

- MLFlow (Tracking & Model Registry)

- GitHub Actions (CI/CD)

- Render (HÃ©bergement cloud API + UI)

- Evidently (Monitoring des donnÃ©es)

- Pytest (Tests unitaires)

## ğŸ” Pipeline MLOps

- ğŸ”¬ 1. EntraÃ®nement & suivi des modÃ¨les
Tracking des expÃ©riences avec MLFlow.

- Stockage centralisÃ© des modÃ¨les dans le Model Registry.

- Optimisation via GridSearchCV.

- Ã‰valuation avec AUC, F1-score et un score mÃ©tier basÃ© sur les coÃ»ts dâ€™erreur.

## ğŸ§  2. Feature Engineering
- CrÃ©ation de variables mÃ©tiers (e.g. Credit/Annuity, EXT_SOURCE).

- Gestion des dÃ©sÃ©quilibres de classes avec SMOTE.

- Construction de caractÃ©ristiques polynomiales et mÃ©tiers.

## ğŸ“ˆ 3. SÃ©lection du meilleur modÃ¨le
- Comparaison de rÃ©gression logistique, forÃªt alÃ©atoire et XGBoost.

- Meilleur modÃ¨le retenu : XGBoost avec features mÃ©tiers.

- Seuil de dÃ©cision optimisÃ© pour maximiser le score mÃ©tier.

## ğŸš€ 4. DÃ©ploiement
- API crÃ©Ã©e avec FastAPI, dÃ©ployÃ©e sur Render.

- Interface Streamlit connectÃ©e Ã  lâ€™API.

- CI/CD avec GitHub Actions.

## ğŸ“Š 5. Monitoring
- Simulation du dÃ©ploiement avec application_test comme donnÃ©es de production.

- Suivi du data drift avec Evidently sur 20 features.

##âš–ï¸ Score mÃ©tier
- FP (faux positifs) = clients fiables refusÃ©s â†’ coÃ»t = 1

- FN (faux nÃ©gatifs) = clients Ã  risque acceptÃ©s â†’ coÃ»t = 10

- Le score mÃ©tier est dÃ©fini par :
score = 1 - (coÃ»t_total / coÃ»t_max)

- Optimisation du seuil de classification pour rÃ©duire ce coÃ»t global.

## ğŸ“Š RÃ©sultats clÃ©s
- Meilleur AUC : 0.756

- Meilleur score mÃ©tier : 0.641

- Bon Ã©quilibre entre performance globale et impact mÃ©tier

- ModÃ¨le robuste mais amÃ©lioration possible du rappel

