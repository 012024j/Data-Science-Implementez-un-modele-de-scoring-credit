## Credit Scoring Engine ‚Äì Impl√©mentation MLOps compl√®te

##
Contexte:

Ce projet a √©t√© r√©alis√© dans le cadre d‚Äôune mission au sein de l‚Äôentreprise fictive "Pr√™t √† d√©penser", sp√©cialis√©e dans les cr√©dits √† la consommation pour des clients sans historique de cr√©dit.
L‚Äôobjectif est de d√©velopper un outil de scoring cr√©dit, permettant de pr√©dire la probabilit√© de remboursement d‚Äôun client et de classifier les demandes en cr√©dit accord√© ou refus√©, tout en suivant une d√©marche MLOps compl√®te.

## üéØ Objectifs du projet
- √âlaborer un mod√®le de classification supervis√©e robuste et interpr√©table.

- Cr√©er un score m√©tier bas√© sur le co√ªt diff√©renci√© des erreurs (faux n√©gatifs / faux positifs).

- Mettre en ≈ìuvre une infrastructure MLOps avec versionning, CI/CD et monitoring.

- D√©ployer le mod√®le via une API FastAPI connect√©e √† une interface utilisateur Streamlit.

- Suivre la d√©rive des donn√©es (data drift) √† l‚Äôaide de la librairie Evidently.

## Stack technique
- Python (Pandas, Scikit-Learn, XGBoost)

- FastAPI (API Backend)

- Streamlit (Frontend de test)

- MLFlow (Tracking & Model Registry)

- GitHub Actions (CI/CD)

- Render (H√©bergement cloud API + UI)

- Evidently (Monitoring des donn√©es)

- Pytest (Tests unitaires)

## Pipeline MLOps

- 1. Entra√Ænement & suivi des mod√®les
Tracking des exp√©riences avec MLFlow.

- Stockage centralis√© des mod√®les dans le Model Registry.

- Optimisation via GridSearchCV.

- √âvaluation avec AUC, F1-score et un score m√©tier bas√© sur les co√ªts d‚Äôerreur.

## 2. Feature Engineering
- Cr√©ation de variables m√©tiers (e.g. Credit/Annuity, EXT_SOURCE).

- Gestion des d√©s√©quilibres de classes avec SMOTE.

- Construction de caract√©ristiques polynomiales et m√©tiers.

## 3. S√©lection du meilleur mod√®le
- Comparaison de r√©gression logistique, for√™t al√©atoire et XGBoost.

- Meilleur mod√®le retenu : XGBoost avec features m√©tiers.

- Seuil de d√©cision optimis√© pour maximiser le score m√©tier.

## 4. D√©ploiement
- API cr√©√©e avec FastAPI, d√©ploy√©e sur Render.

- Interface Streamlit connect√©e √† l‚ÄôAPI.

- CI/CD avec GitHub Actions.

## 5. Monitoring
- Simulation du d√©ploiement avec application_test comme donn√©es de production.

- Suivi du data drift avec Evidently sur 20 features.

##
Score m√©tier
- FP (faux positifs) = clients fiables refus√©s ‚Üí co√ªt = 1

- FN (faux n√©gatifs) = clients √† risque accept√©s ‚Üí co√ªt = 10

- Le score m√©tier est d√©fini par :
score = 1 - (co√ªt_total / co√ªt_max)

- Optimisation du seuil de classification pour r√©duire ce co√ªt global.

## R√©sultats cl√©s
- Meilleur AUC : 0.756

- Meilleur score m√©tier : 0.641

- Bon √©quilibre entre performance globale et impact m√©tier

- Mod√®le robuste mais am√©lioration possible du rappel


## Lien de d√©monstration
- API (FastAPI) 
- Interface (Streamlit)

## Test unitaire
- Tests r√©alis√©s :

- V√©rification que le mod√®le utilise bien les 20 features s√©lectionn√©es

- V√©rification de l‚Äôex√©cution sur un batch de donn√©es

- V√©rification que les probabilit√©s sont bien entre 0 et 1

## Explicabilit√©
- Importance globale des variables via SHAP

- Explications locales pour chaque pr√©diction (exemples individuels)

## Auteur
- Oumou Faye
- Projet r√©alis√© dans le cadre du parcours Data Scientist CentraleSup√©lec - OpenClassrooms
- Mentor : Medina Hadjem
